<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

	<property>
		<name>http.agent.name</name>
		<value>Info Crawler</value>
	</property>

	<property>
		<name>hadoop.tmp.dir</name>
		<value>/tmp</value>
		<description>Tmp folder</description>
	</property>


	<property>
		<name>db.max.outlinks.per.page</name>
		<value>-1</value>
		<description>NCI OVERRIDE: NCI has lots of pages that have lots of links (and sitemap.xml is all links).  This is being set to unlimited.</description>
	</property>
	
	<property>
		<name>db.signature.class</name>
		<value>org.apache.nutch.crawl.TextProfileSignature</value>
		<description>NCI OVERRIDE: TextProfileSignature might be going overboard, but the MD5Signature class is resulting in unidentified dupes.</description>
	</property>
	
	<property>
		<name>db.fetch.interval.default</name>
		<!--<value>1202400</value>-->
		<value>86400</value>
		<description>NCI OVERRIDE: Setting this to about 14 days.  Technically, 14 days minus 2 hrs.  20151113 setting to every night for testing </description>
	</property>

	<property>
		<name>db.fetch.interval.max</name>
		<value>7776000</value>
		<description>NCI OVERRIDE: The maximum number of seconds between re-fetches of a page(90 days). After this period every page in the db will be re-tried, no matter what is its status.
		</description>
	</property>	

	<property>
		<name>db.fetch.retry.max</name>
		<value>30</value>
		<description>NCI OVERRIDE: Things on the network can be sketchy, so I am upping this to a high value so that we do not accidently remove things that are having issues.  A value of 30 *should* basically mean that we should retry the item for about a month before skipping it.</description>
	</property>	

	<property>
		<name>http.content.limit</name>
  		<value>-1</value>
  		<description>NCI OVERRIDE: CGov pages are too big for the default, so for now we are using unlimited.</description>
	</property>
	
	<property>
		<name>indexer.max.title.length</name>
		<value>-1</value>
		<description>The maximum number of characters of a title that are indexed. A value of -1 disables this check.</description>
	</property>

	<property>
		<name>http.timeout</name>
		<value>10000</value>
		<description>NCI OVERRIDE: Upped to 20sec from 10sec to allow time for www.cancer.gov to generate its sitemap.xml file. 20151113 - it seems 20sec is not long enough, so reverting to 10sec</description>
	</property>
	
	<property>
	  <name>fetcher.threads.fetch</name>
	  <value>100</value>
	  <description>NCI OVERRIDE: Upping this to 100</description>
	</property> 

	<property>
	  <name>fetcher.threads.per.queue</name>
	  <value>2</value>
	  <description>This number is the maximum number of threads that should be allowed to access a queue at one time. Replaces
	    deprecated parameter 'fetcher.threads.per.host'. 
	[BP] Setting this to 1 so that the delay is honored.  Having this set to 10 threads kills some sites (CCR).
	[BP] Upping this to 2 so we can override crawl delay for some sites (CCR)
	  </description>
	</property> 

	<!-- If fetcher.threads.per.queue == 1 then comment the lines below -->
	<property>
	  <name>fetcher.server.min.delay</name>
	  <value>0.3</value>
	  <description>NCI OVERRIDE: We need to ignore crawl delays in robots.txt for many Drupal sites which are set at 10 sec.  Setting too many threads will kill sites.  This setting acts like fetcher.server.delay, but </description>
	</property>


	<!-- If fetcher.threads.per.queue == 1 then uncomment the lines below
	<property>
	  <name>fetcher.server.delay</name>
	  <value>0.5</value>
	  <description>NCI OVERRIDE: Attempting this value to not kill slow servers.  Would be nice to set this per host.
[BP] Setting this to 1 sec delay as we only have 1 thread per site.  This will definately make certain sites *much* slower to crawl.  (CGov would be at least 4000+ seconds...)
</description>
	</property> 
	-->



	<property>
		<name>plugin.includes</name>
			<value>protocol-http|urlfilter-(regex|domain|suffix)|parse-(html|tika|metatags|replace)|language-identifier|index-(basic|anchor|metadata|replace|more)|indexer-elastic|scoring-opic|urlnormalizer-(pass|regex|basic)</value>
	</property>	


<property>
    <name>index.replace.regexp</name>
    <value>
	
	url:searchurl=/(https|http)\:..//

	title:searchtitle=/=/=/

	hostmatch=www.cancer.gov
        title:searchtitle=/ - National Cancer Institute//
		searchtitle:searchtitle=/(.*)—Patient Version/$1/2
		searchtitle:searchtitle=/(.*)—Health Professional Version/$1/2
		searchtitle:searchtitle=/(.*)—Versión para pacientes/$1/2
		searchtitle:searchtitle=/(.*)—Versión para profesionales de salud/$1/2


	#Replace DCEGs Title
	hostmatch=dceg.cancer.gov
      title:searchtitle=/ - National Cancer Institute//
	hostmatch=proteomics.cancer.gov
      title:searchtitle=/ - Office of Cancer Clinical Proteomics Research - National Cancer Institute//
	hostmatch=imaging.cancer.gov
      title:searchtitle=/ - Cancer Imaging Program - National Cancer Institute//
	hostmatch=cancergenome.nih.gov
      title:searchtitle=/ - TCGA//


    </value>
  </property>


	<property>
		<name>metatags.names</name>
		<value>*</value>
		<description> Names of the metatags to extract, separated by ','. Use '*' to extract all metatags. Prefixes the names with 'metatag.' in the parse-metadata. For instance to index description and keywords, you need to activate the plugin index-metadata and set the value of the parameter 'index.parse.md' to 'metatag.description,metatag.keywords'.
		</description>
	</property>

	<property>
	  <name>index.parse.md</name>
	  <value>metatag.description,metatag.keywords,metatag.content-language,metatag.dcterms.type</value>
	  <description>
	  Comma-separated list of keys to be taken from the parse metadata to generate fields.
	  Can be used e.g. for 'description' or 'keywords' provided that these values are generated
	  by a parser (see parse-metatags plugin)
	  </description>
	</property>



	<property>
		<name>lang.extraction.policy</name>
		<value>detect</value>
		<description>NCI OVERRIDE: We only want to detect the language it it exists in the headers/metatags</description>
	</property>

 	<!-- Elasticsearch properties -->

	<property>
	  <name>elastic.host</name>
	  <value>${ES_HOST}</value>
	  <description>The hostname to send documents to using TransportClient. Either host and port must be defined or cluster.</description>
	</property>

	<property>
	  <name>elastic.port</name>
	  <value>${ES_CLUSTER_PORT_235}</value>
	  <description>
	  </description>
	</property>

	<property>
	  <name>elastic.cluster</name>
	  <value>${ES_CLUSTER_NAME_235}</value>
	  <description>The cluster name to discover. Either host and port must be defined or cluster.</description>
	</property>

	<property>
	  <name>elastic.index</name>
	  <value>${ES_INDEX_NAME}</value>
	  <description>Default index to send documents to.</description>
	</property>
	
	<property>
	  <name>elastic.max.bulk.docs</name>
	  <value>250</value>
	  <description>Maximum size of the bulk in number of documents.</description>
	</property>

	<property>
	  <name>elastic.max.bulk.size</name>
	  <value>2500500</value>
	  <description>Maximum size of the bulk in bytes.</description>
	</property>

</configuration>
